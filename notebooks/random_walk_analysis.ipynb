{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Walk Experiment Analysis\n",
        "\n",
        "This notebook analyzes results from the random walk learning experiment.\n",
        "\n",
        "## Experiment Overview\n",
        "\n",
        "The random walk experiment trains networks on data where each image differs from the previous by exactly 1 pixel change. This creates data with much lower Lipschitz continuity than uniform random noise, making memorization/interpolation harder.\n",
        "\n",
        "### Experiments included:\n",
        "1. **Baseline**: Train on random walk data\n",
        "2. **Smoothness Analysis**: Measure function smoothness\n",
        "3. **Two-Stage Learning**: \n",
        "   - Variant A: Network_2 on walk data labeled by Network_1\n",
        "   - Variant B: Network_2 on uniform data labeled by Network_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path.cwd().parent / 'src'))\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.utils.config import ExperimentConfig\n",
        "from src.analysis.visualization import plot_random_walk_comparison\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load random walk experiment results\n",
        "results_path = ExperimentConfig.get_results_save_path('random_walk_experiment')\n",
        "print(f\"Loading results from: {results_path}\")\n",
        "\n",
        "with open(results_path, 'rb') as f:\n",
        "    results = pickle.load(f)\n",
        "\n",
        "print(\"\\nResults loaded successfully!\")\n",
        "print(f\"Available keys: {list(results.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Training Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display baseline results\n",
        "baseline = results['baseline']\n",
        "\n",
        "print(\"Baseline Training Results:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Training accuracy: {baseline['final_train_acc']:.2f}%\")\n",
        "print(f\"Test (walk continuation): {baseline['test_acc_walk']:.2f}%\")\n",
        "print(f\"Test (uniform random): {baseline['test_acc_uniform']:.2f}%\")\n",
        "print(f\"\\nTraining samples: {baseline['n_samples']}\")\n",
        "print(f\"Epochs: {baseline['epochs']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "history = baseline['training_history']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Training accuracy\n",
        "axes[0].plot(history['train_acc'], linewidth=2, label='Training Accuracy')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "axes[0].set_title('Training Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].legend()\n",
        "\n",
        "# Training loss\n",
        "axes[1].plot(history['train_loss'], linewidth=2, color='orange', label='Training Loss')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].set_title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smoothness Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display smoothness metrics\n",
        "smoothness = results['smoothness']\n",
        "\n",
        "print(\"Smoothness Metrics:\")\n",
        "print(\"=\"*50)\n",
        "for metric, value in smoothness.items():\n",
        "    print(f\"{metric:20s}: {value:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize smoothness metrics\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "metrics = list(smoothness.keys())\n",
        "values = list(smoothness.values())\n",
        "\n",
        "bars = ax.barh(metrics, values, color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax.set_xlabel('Metric Value', fontsize=12)\n",
        "ax.set_title('Smoothness Metrics for Random Walk Model', fontsize=14, fontweight='bold')\n",
        "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add value labels\n",
        "for bar, value in zip(bars, values):\n",
        "    ax.text(value, bar.get_y() + bar.get_height()/2, \n",
        "            f'{value:.4f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two-Stage Learning Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display two-stage learning results\n",
        "two_stage = results['two_stage']\n",
        "\n",
        "print(\"Two-Stage Learning Results:\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nVariant A (Walk Data):\")\n",
        "print(f\"  Training accuracy: {two_stage['variant_a_walk']['final_train_acc']:.2f}%\")\n",
        "print(f\"  Agreement with Network_1: {two_stage['variant_a_walk']['agreement']:.2f}%\")\n",
        "\n",
        "print(\"\\nVariant B (Uniform Data):\")\n",
        "print(f\"  Training accuracy: {two_stage['variant_b_uniform']['final_train_acc']:.2f}%\")\n",
        "print(f\"  Agreement with Network_1: {two_stage['variant_b_uniform']['agreement']:.2f}%\")\n",
        "\n",
        "# Calculate difference\n",
        "diff = two_stage['variant_b_uniform']['agreement'] - two_stage['variant_a_walk']['agreement']\n",
        "print(f\"\\nDifference (Uniform - Walk): {diff:+.2f}%\")\n",
        "print(\"\\nInterpretation:\")\n",
        "if diff > 5:\n",
        "    print(\"  Uniform data shows HIGHER agreement - easier to learn Network_1's function\")\n",
        "elif diff < -5:\n",
        "    print(\"  Walk data shows HIGHER agreement - unexpected result!\")\n",
        "else:\n",
        "    print(\"  Similar agreement - data structure may not matter significantly\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves for both variants\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Variant A\n",
        "history_a = two_stage['variant_a_walk']['history']\n",
        "axes[0].plot(history_a['train_acc'], linewidth=2, label='Walk Data')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "axes[0].set_title('Variant A: Training on Walk Data', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].legend()\n",
        "\n",
        "# Variant B\n",
        "history_b = two_stage['variant_b_uniform']['history']\n",
        "axes[1].plot(history_b['train_acc'], linewidth=2, color='orange', label='Uniform Data')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "axes[1].set_title('Variant B: Training on Uniform Data', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the built-in visualization function\n",
        "plot_random_walk_comparison(\n",
        "    results,\n",
        "    save_path=str(Path.cwd().parent / 'figures' / 'random_walk_comparison.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"KEY FINDINGS FROM RANDOM WALK EXPERIMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. BASELINE TRAINING:\")\n",
        "print(f\"   - Can achieve {baseline['final_train_acc']:.2f}% training accuracy\")\n",
        "print(f\"   - Walk continuation test: {baseline['test_acc_walk']:.2f}%\")\n",
        "print(f\"   - Uniform random test: {baseline['test_acc_uniform']:.2f}%\")\n",
        "\n",
        "print(\"\\n2. FUNCTION SMOOTHNESS:\")\n",
        "print(f\"   - Gradient norm: {smoothness['gradient_norm']:.4f}\")\n",
        "print(f\"   - Lipschitz constant: {smoothness['lipschitz_constant']:.4f}\")\n",
        "print(f\"   - Local variation: {smoothness['local_variation']:.4f}\")\n",
        "\n",
        "print(\"\\n3. TWO-STAGE LEARNING:\")\n",
        "print(f\"   - Walk data agreement: {two_stage['variant_a_walk']['agreement']:.2f}%\")\n",
        "print(f\"   - Uniform data agreement: {two_stage['variant_b_uniform']['agreement']:.2f}%\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n4. INTERPRETATION:\")\n",
        "if baseline['test_acc_walk'] < 15 and baseline['test_acc_uniform'] < 15:\n",
        "    print(\"   ✓ Random walk data is very difficult to generalize from\")\n",
        "    print(\"   ✓ Networks can memorize but not generalize to new random data\")\n",
        "\n",
        "if two_stage['variant_b_uniform']['agreement'] > two_stage['variant_a_walk']['agreement'] + 10:\n",
        "    print(\"   ✓ Uniform data shows MUCH higher agreement\")\n",
        "    print(\"   ✓ Network learns smoother functions on uniform random data\")\n",
        "    print(\"   ✓ Lipschitz continuity MATTERS for function learnability\")\n",
        "elif abs(two_stage['variant_b_uniform']['agreement'] - two_stage['variant_a_walk']['agreement']) < 5:\n",
        "    print(\"   ✓ Similar agreement on both data types\")\n",
        "    print(\"   ✓ Data structure may not significantly affect learnability\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
